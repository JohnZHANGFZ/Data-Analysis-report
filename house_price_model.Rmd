---
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# import packages
# install.packages("pbkrtest")
# install.packages("car")
# install.packages("readr")
# install.packages("tidyverse")
# install.packages("pander")
# install.packages("ggplot2")
# install.packages("MASS")
library(readr)
library(tidyverse)
library(pander)
library(ggplot2)
library(car)
library(MASS)
library(gridExtra)
```

# Step 0: Divide data into training and testing
```{r}
# import data
house_price <- read.csv("modified_house_price.csv")

set.seed(123) # set seed for reproducibility
n <- nrow(house_price)
training_indices <- sample(1:n, size = round(0.8 * n))
train <- house_price[training_indices, ]
test <- house_price[-training_indices, ]
```

## Exploratory Data Analysis (EDA)
## Graphical Summaries
## draw boxplots for each variable
```{r}
#new <- subset(data2, select = c(price, square, livingRoom,
#                               drawingRoom, kitchen, bathRoom, 
#                               communityAverage, followers, 
#                               renovationCondition, buildingType))

box_Followers <- ggplot(train, aes(x = "", y = followers)) + 
  geom_boxplot() + ggtitle("Followers")
box_Square <- ggplot(train, aes(x = "", y = square)) + 
  geom_boxplot() + ggtitle("Square")
box_LivingRoom <- ggplot(train, aes(x = "", y = livingRoom)) + 
  geom_boxplot() + ggtitle("Living Room")
box_DrawingRoom <- ggplot(train, aes(x = "", y = drawingRoom)) + 
  geom_boxplot() + ggtitle("Drawing Room")
box_Kitchen <- ggplot(train, aes(x = "", y = kitchen)) + 
  geom_boxplot() + ggtitle("Kitchen")
box_BathRoom <- ggplot(train, aes(x = "", y = bathRoom)) +
  geom_boxplot() + ggtitle("Bath Room")
box_CommunityAverage <- ggplot(train, aes(x = "", y = communityAverage)) +
  geom_boxplot() + ggtitle("Community Average")
box_RenovationCondition <- ggplot(train, aes(x = "", y = renovationCondition)) +
  geom_boxplot() + ggtitle("Renovation Condition")


grid.arrange(box_Followers, box_Square, box_LivingRoom, 
             box_DrawingRoom, box_Kitchen, box_BathRoom, 
             box_CommunityAverage, box_RenovationCondition,nrow=2)
```

```{r}
bar_BuildingType <- train %>% 
  ggplot(aes(x=buildingType)) +
  geom_bar(color='black', fill='steelblue') +
  labs(title="Building Type") + 
  coord_flip()

bar_BuildingType <- train %>% 
  ggplot(aes(x=buildingType)) +
  geom_bar(color='black', fill='steelblue') +
  labs(title="Building Type") + 
  coord_flip()
bar_BuildingType
```

# Step 1: Choose a starting model
```{r}
model_full <- lm(price ~ followers + square + livingRoom + drawingRoom + 
                   kitchen + bathRoom + buildingType + communityAverage + 
                   renovationCondition, data = train)
```

# Step 2: Explore model transformations
# check the normality of the residuals
```{r}
par(mfrow = c(2, 2))
plot(model_full)

train <- train %>% mutate(followers = followers + 1)
train <- train %>% mutate(livingRoom = livingRoom + 1)
train <- train %>% mutate(drawingRoom = drawingRoom + 1)
train <- train %>% mutate(kitchen = kitchen + 1)
train <- train %>% mutate(bathRoom = bathRoom + 1)

summary(powerTransform(cbind(train$price,
                             train$followers,
                             train$square,
                             train$livingRoom,
                             train$drawingRoom,
                             train$kitchen,
                             train$bathRoom,
                             train$communityAverage)))
```

```{r}
transformed_train <- train %>% mutate(transformed_price = price^(0.18),
                                      transformed_followers = followers^(-0.11),
                                      transformed_square = square^(0.07),
                                      transformed_livingRoom = livingRoom^(0.46),
                                      transformed_drawingRoom = drawingRoom^(0.93),
                                      transformed_kitchen = kitchen^(1.97),
                                      transformed_bathRoom = bathRoom^(-1.2),
                                      transformed_communityAverage = communityAverage^(-0.33))

transformed_model_full <- lm(transformed_price ~ . -followers -square 
                             -livingRoom -drawingRoom -kitchen -bathRoom 
                             -bathRoom -communityAverage, data = transformed_train)
```


# Step 3: Check for multicollinearity
```{r}
vif(transformed_model_full)
# The highest VIF value is for transformed_square (3.511364), 
# but this value is significantly lower than the usual thresholds (5 or 10) 
# used to indicate serious multicollinearity issues.

# The VIF values for other variables are even lower, 
# suggesting that there is not strong linear correlation among them.

# No Need to Remove Any Variables: Based on the current VIF results, 
# there's no need to remove any predictors from our model, 
# as none of the variables have VIFs close to or exceeding 5.
```

# Step 4: Automated selection vs. manual selection
## Candidate model 1: automated selection
```{r}
model_auto <- step(transformed_model_full, direction = "both")
summary(model_auto)
```

## Candidate model 2: manually selection
```{r}
model_manual <- lm(price ~ followers + square, data = train)
summary(model_manual)
```

```{r}
# compare the two models
anova(model_auto, model_full)
anova(model_manual, model_full)
```

# Step 5: Leverage, Outlier, and Influential Point Analysis
```{r}
# use hatvalues(), cooks.distance(), rstandard() to check

# compare the two models
par(mfrow = c(1, 1))
plot(model_auto$residuals ~ model_auto$fitted.values)

# Model Validation on Test Data
```